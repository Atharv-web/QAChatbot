{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "957b50e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google import genai\n",
    "from pinecone import Pinecone\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "load_dotenv()\n",
    "\n",
    "PINECONE_API_KEY= os.getenv('PINECONE_API_KEY')\n",
    "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY) # creating the pinecone database instance\n",
    "INDEX_NAME = \"qa-chatbot\"\n",
    "NAMESPACE = \"bizz-docs-sample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "568f25e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy data\n",
    "business_documents = [\n",
    "    # OPENAI DOCS\n",
    "    {\n",
    "        \"_id\": \"openai_doc1\",\n",
    "        \"content\": \"ChatGPT is OpenAI's conversational AI assistant, capable of engaging in natural, context-aware dialogue across a wide range of topics. It is used for tasks like writing assistance, tutoring, customer support, and ideation. ChatGPT supports multimodal input (text and images), code generation, and advanced memory features for personalized experiences.\",\n",
    "        \"category\": \"product_info\",\n",
    "        \"product_name\": \"ChatGPT\"\n",
    "    },\n",
    "    {\n",
    "        \"_id\": \"openai_doc2\",\n",
    "        \"content\": \"OpenAI Codex is the engine behind GitHub Copilot and is designed to translate natural language into code. It supports over a dozen programming languages and enables developers to build applications faster by generating code snippets, completing functions, and even writing entire modules based on descriptive input.\",\n",
    "        \"category\": \"product_info\",\n",
    "        \"product_name\": \"Codex\"\n",
    "    },\n",
    "    {\n",
    "        \"_id\": \"openai_doc3\",\n",
    "        \"content\": \"DALL·E is a generative AI model by OpenAI that creates images from textual prompts. With support for inpainting, editing, and realistic rendering, DALL·E empowers artists, marketers, and developers to turn creative ideas into visual content. It's particularly popular for concept art, design mockups, and marketing illustrations.\",\n",
    "        \"category\": \"product_info\",\n",
    "        \"product_name\": \"DALL·E\"\n",
    "    },\n",
    "    {\n",
    "        \"_id\": \"openai_doc4\",\n",
    "        \"content\": \"Whisper is OpenAI's automatic speech recognition (ASR) system trained on a large, diverse dataset of multilingual and multitask audio. It delivers high-accuracy transcription, translation, and speech-to-text capabilities. Whisper is open-source and used in voice assistants, accessibility apps, and real-time transcription tools.\",\n",
    "        \"category\": \"product_info\",\n",
    "        \"product_name\": \"Whisper\"\n",
    "    },\n",
    "\n",
    "# META DOCS\n",
    "    {\n",
    "        \"_id\": \"meta_doc1\",\n",
    "        \"content\": \"Meta's Quest 3 is a mixed reality headset that offers a powerful VR and AR experience. Equipped with full-color passthrough, spatial audio, and Snapdragon XR2 Gen 2, it is ideal for gaming, collaboration, and immersive learning. It supports a wide range of apps from the Meta Quest Store and integrates with hand tracking for a controller-free experience.\",\n",
    "        \"category\": \"product_info\",\n",
    "        \"product_name\": \"Meta Quest 3\"\n",
    "    },\n",
    "    {\n",
    "        \"_id\": \"meta_doc2\",\n",
    "        \"content\": \"Threads is Meta's microblogging social platform designed for close-knit conversations and sharing real-time updates. Integrated with Instagram, Threads allows users to post text, images, and videos while following their interests. Its minimal interface and privacy-first design make it ideal for creators and casual users alike.\",\n",
    "        \"category\": \"product_info\",\n",
    "        \"product_name\": \"Threads\"\n",
    "    },\n",
    "    {\n",
    "        \"_id\": \"meta_doc3\",\n",
    "        \"content\": \"Llama 3 is Meta's latest open-source large language model (LLM), built for research and enterprise applications. It provides state-of-the-art performance on reasoning, coding, and multilingual benchmarks, and can be fine-tuned for various tasks such as summarization, chatbots, and content generation.\",\n",
    "        \"category\": \"product_info\",\n",
    "        \"product_name\": \"Llama 3\"\n",
    "    },\n",
    "\n",
    "# AMAZON DOCS\n",
    "    {\n",
    "        \"_id\": \"amazon_doc1\",\n",
    "        \"content\": \"Amazon Web Services (AWS) is the world's most comprehensive cloud computing platform, offering over 200 services including compute, storage, networking, machine learning, and security. Businesses of all sizes rely on AWS for scalable infrastructure, rapid deployment, and global reach.\",\n",
    "        \"category\": \"product_info\",\n",
    "        \"product_name\": \"AWS\"\n",
    "    },\n",
    "    {\n",
    "        \"_id\": \"amazon_doc2\",\n",
    "        \"content\": \"Alexa is Amazon's intelligent voice assistant that powers Echo devices and other smart home integrations. With Alexa, users can control smart devices, play music, get weather updates, and access a wide range of skills. Alexa's AI continues to evolve, providing more natural conversations and improved contextual understanding.\",\n",
    "        \"category\": \"product_info\",\n",
    "        \"product_name\": \"Alexa\"\n",
    "    },\n",
    "    {\n",
    "        \"_id\": \"amazon_doc3\",\n",
    "        \"content\": \"Amazon Prime is a premium membership that offers exclusive benefits like free one-day delivery, Prime Video streaming, Prime Music, and early access to deals. Prime is designed to provide convenience, entertainment, and savings for frequent Amazon shoppers.\",\n",
    "        \"category\": \"product_info\",\n",
    "        \"product_name\": \"Amazon Prime\"\n",
    "    },\n",
    "\n",
    "# PINECONE DOCS\n",
    "    {\n",
    "        \"_id\": \"pinecone_doc1\",\n",
    "        \"content\": \"Pinecone is a vector database service that enables high-speed, scalable similarity search for machine learning applications. It allows developers to store, update, and query vector embeddings in real time, making it ideal for applications like recommendation engines, semantic search, and fraud detection.\",\n",
    "        \"category\": \"product_info\",\n",
    "        \"product_name\": \"Pinecone Vector DB\"\n",
    "    },\n",
    "    {\n",
    "        \"_id\": \"pinecone_doc2\",\n",
    "        \"content\": \"Pinecone's hybrid search feature enables combined filtering and vector similarity search, allowing users to retrieve contextually relevant results while applying metadata constraints. This is particularly useful for e-commerce, knowledge retrieval, and personalized search solutions.\",\n",
    "        \"category\": \"product_info\",\n",
    "        \"product_name\": \"Hybrid Search\"\n",
    "    },\n",
    "    {\n",
    "        \"_id\": \"pinecone_doc3\",\n",
    "        \"content\": \"The Pinecone Serverless architecture eliminates the need to manage infrastructure, automatically scaling based on traffic and usage. With zero maintenance and built-in security, it simplifies deployment for AI-powered applications with minimal operational overhead.\",\n",
    "        \"category\": \"product_info\",\n",
    "        \"product_name\": \"Pinecone Serverless\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6a1411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_upload_db(documents,INDEX_NAME,NAMESPACE):\n",
    "    # Creating an index in the database\n",
    "    if not pc.has_index(INDEX_NAME):\n",
    "        pc.create_index_for_model(\n",
    "            name=INDEX_NAME,\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\",\n",
    "            embed = {          # using the pinecone database inbuilt embedding model, which will embed the docs and the user question also, during semantic search.    \n",
    "                \"model\":\"llama-text-embed-v2\",   # default embedding model\n",
    "                \"field_map\": {\"text\": \"content\"}\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # go to pinecone and check the created index and copy paste the host url in the host \n",
    "    host = \"https://qa-chatbot-aheg7k4.svc.aped-4627-b74a.pinecone.io\" # pinecone instance using aws cloud.\n",
    "    index = pc.Index(host=host)\n",
    "    index.upsert_records(NAMESPACE,documents) # remember the namespace is \"bizz-docs-sample\"\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87a6fb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data(user_message,index,NAMESPACE):\n",
    "    query = {\n",
    "        \"inputs\": {\"text\": user_message},\n",
    "        \"top_k\": 5\n",
    "    }\n",
    "\n",
    "    results = index.search(\n",
    "        namespace=NAMESPACE,\n",
    "        query=query,\n",
    "        fields=[\"content\",\"category\"]\n",
    "    )\n",
    "\n",
    "    retrieved_context = [{\n",
    "        \"id\": hit['_id'],\n",
    "        \"category\": hit['fields']['category'],\n",
    "        \"llm_context\":hit['fields']['content'],\n",
    "        } for hit in results['result']['hits']\n",
    "    ]\n",
    "\n",
    "    return retrieved_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08264a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatting the gemini response into clean text.\n",
    "def format_response(gemini_output):\n",
    "    clean_text = re.sub(r\"\\*\\*(.*?)\\*\\*\", r\"\\1\", gemini_output)\n",
    "    clean_text = re.sub(r\"^\\s*[\\*\\-]\\s*\", \"- \", clean_text, flags=re.MULTILINE)\n",
    "    clean_text = re.sub(r'\\n{2,}', '\\n\\n', clean_text)\n",
    "    return clean_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1813357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(user_message, retrieved_docs_cache,session_history):\n",
    "    history_context = \"\\n\".join([\n",
    "        f\"{turn['role'].capitalize()}: {turn['content']}\" for turn in session_history[-3:]\n",
    "    ])\n",
    "\n",
    "    context_text = \"\\n\".join([\n",
    "        doc['llm_context'] for doc in retrieved_docs_cache\n",
    "    ])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a Business Domain QA Chatbot powered by RAG.\n",
    "    Answer the user's question based on the context provided below.\n",
    "    Do NOT engage in casual, personal, or off-topic conversations.\n",
    "    If unsure, say \\\"I don't have enough information to answer that.\\\"\n",
    "\n",
    "    Context:\n",
    "    {context_text}\n",
    "\n",
    "    Conversation so far:\n",
    "    {history_context}\n",
    "\n",
    "    Current Question:\n",
    "    {user_message}\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def bizz_chat(prompt):\n",
    "    llm = genai.Client()\n",
    "    response = llm.models.generate_content(\n",
    "        model='gemini-2.5-flash',\n",
    "        contents=prompt\n",
    "    )\n",
    "    return format_response(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcd2ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_chatbot():\n",
    "    index = initialize_upload_db(business_documents, INDEX_NAME, NAMESPACE)\n",
    "    if index is None:\n",
    "        return\n",
    "\n",
    "    session_history = []\n",
    "    retrieved_docs_cache = []\n",
    "\n",
    "    print(\"Welcome to the Business QA Chatbot. Type 'exit' to quit.\")\n",
    "    while True:\n",
    "        user_message = input(\"\\nEnter your query: \")\n",
    "        if user_message.lower() in ['exit', 'quit']:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        session_history.append({\"role\": \"user\", \"content\": user_message})\n",
    "        new_context = retrieve_data(user_message, index, NAMESPACE)\n",
    "        retrieved_docs_cache.extend(new_context)\n",
    "\n",
    "        prompt = build_prompt(user_message, retrieved_docs_cache, session_history)\n",
    "        response = bizz_chat(prompt)\n",
    "        print(\"\\nResponse:\\n\",response)\n",
    "        session_history.append({\"role\": \"bot\", \"content\": response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa8b05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chatbot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
